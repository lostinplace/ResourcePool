I started this problem off thinking I'd be able to come up with some cool and elegant solution using a tree of concurrenthashmaps, but as I started working on the problem it became clear that not only was my idea not that well conceived, it also required a deeper understanding of java than I possessed, so I went back to what I've styled,  "the queue approach".

This approach focuses on the specification that acquisitions and releases occur frequently while adds and removes occur infrequently.  When I started I set out the requirements that acquisitions should be possible in constant time and releases at log n (allowing for lookup of the resources) but found that I couldn't mitigate the cost of tracking the acquired resources.  It looks like I'm stuck with log n acquisition time because of bookkeeping.

I ended up implementing an ordered set index manager for all of the managed objects (using system.identityhashcode)  but I keep going back and forth on this. a con of this approach is that it requires a superfluous structure, but on the plus side it dramatically improves theoretical add times:  if n is the number of items managed by the pool and a is the number currently acquired, the cost of a containment search for the available and acquired collections is log a + log (n-a) or log an-a^2  meaning that for  significantly unbalanced usage of the pool add/remove time is higher than would be under the single resource approach.  Ultimately it stayed in because I figured I had spent enough time working on the problem, though if I had to I would come back to my "multiple resource trackers" choice and evaluate it against actual use cases.

Another "benefit" of the resource index manager approach is that it gave me something to synchLock when I wanted seize control over the pool, however I can't shake the feeling that there's a way to conduct most of these operations without locking (though I suspect there would be some pretty painful race conditions if I were to do so) 

I found that the more I worked on the problem, the more defensive I became regarding race conditions, and the more liberally I used synchLocks to control the state of the available resource queue during add and remove operations.  I think that there's a way to ensure the availability without such a defensive posture, but it may come at increased complexity/storage cost, and I didn't have the time to significantly explore any of my thoughts on this.

AS a whole I feel like the pool is pretty threadsafe, though I do wonder if there's some java trickery that I'm currently unaware of that I could use to tighten it further.  Additionally I feel like there are a couple of places where experimentation would reveal some added efficiencies in the add/remove pipeline, and my mind is grinding away trying to thing of a way to appropriately handle acquired resources without tracking them explicitly and forcing log n on acquire/release operations, but once again.  no time.

Overall I thought this was a good exercise,  it had been a long time since I've written anything in java, and I hadn't then gotten a chance to play around with the concurrent namespace at all.  

